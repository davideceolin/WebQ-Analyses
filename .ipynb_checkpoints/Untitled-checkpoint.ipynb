{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.zeros(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf 0.270238095238\n",
      "svr_lin -1.12762051095\n",
      "svr_poly -0.294695497912\n",
      "gnb 0.329166666667\n",
      "svc 0.653333333333\n",
      "svc5 0.653333333333\n",
      "---------\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "#import documents\n",
    "#import assessments\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVR, SVC\n",
    "import csv \n",
    "from sklearn.externals import joblib\n",
    "\n",
    "gnb = GaussianNB()\n",
    "pd.options.mode.chained_assignment = None \n",
    "ent = []\n",
    "\n",
    "pd2 = pd.read_csv(\"~/document.csv\",quotechar=\"\\\"\",sep=\";\",header=0)\n",
    "for i in range(0,50):\n",
    "    for x in json.loads(pd2.iloc[i].entities):\n",
    "        colname = x['disambiguated']['dbpedia'] if 'disambiguated' in x and 'dbpedia' in x['disambiguated'] else x['text']\n",
    "        pd2[colname] = np.zeros(50)\n",
    "        ent.append(colname)\n",
    "for i in range(0,50):\n",
    "    for x in json.loads(pd2.iloc[i].entities):\n",
    "        colname = x['disambiguated']['dbpedia'] if 'disambiguated' in x and 'dbpedia' in x['disambiguated'] else x['text']\n",
    "        pd2[colname][i] = float(x['relevance'])\n",
    "\n",
    "#print pd2\n",
    "\n",
    "assessments = pd.read_csv(\"./data2.csv\",sep=\";\", header=0,)\n",
    "\n",
    "grouped_assessment = assessments.groupby('target').mean()#['overallQuality']\n",
    "pd2 = pd2.set_index('url')\n",
    "\n",
    "pd2 = pd.concat([pd2, grouped_assessment], axis=1, join='inner')\n",
    "\n",
    "l = [x for x in list(pd2.columns.values) if x not in list(assessments.columns.values)]\n",
    "l = [x for x in l if x not in ['entities','title','source','_id']]\n",
    "l2 = [x.encode(\"utf-8\") for x in l]\n",
    "with open('feats.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(l2)\n",
    "#print pd2.columns.values\n",
    "X = pd2[l]\n",
    "y = np.asarray(pd2['overallQuality'])\n",
    "#X = pd2[x for x in list(pd2.columns.values) if x not in list(assessments.columns.values)]\n",
    "for x in ['overallQuality']:\n",
    "    y_clf = np.asarray(pd2[x], dtype=\"|S6\")\n",
    "    y_gnb = np.asarray(pd2[x], dtype=\"|S6\")\n",
    "    y_svr_lin = np.asarray(pd2[x])\n",
    "    y_svr_poly = np.asarray(pd2[x])\n",
    "    y_class = np.asarray([0 if x<=1 else 2 if x==5 else 1 for x in pd2[x]])\n",
    "    clf = SGDClassifier(alpha=0.00005, n_iter=1000)\n",
    "    svr_lin = SVR(kernel='linear', C=1e3)\n",
    "    svr_poly = SVR(kernel='poly', C=1e3, degree=2)\n",
    "    gnb = GaussianNB()\n",
    "    svc = SVC(kernel='linear', C=1e3)\n",
    "    clf.fit(X, y_clf)\n",
    "    svr_lin.fit(X, y_svr_lin)\n",
    "    svr_poly.fit(X, y_svr_poly)\n",
    "    gnb.fit(X, y_gnb)\n",
    "    #svc.fit(X, y_svc)\n",
    "    \n",
    "    scores_clf = cross_validation.cross_val_score(clf, X, y_clf, cv=10)\n",
    "    scores_svr_lin = cross_validation.cross_val_score(svr_lin, X, y_svr_lin, cv=10)\n",
    "    scores_svr_poly = cross_validation.cross_val_score(svr_poly, X, y_svr_poly, cv=10)\n",
    "    scores_gnb = cross_validation.cross_val_score(gnb, X, y_gnb, cv=10)\n",
    "    scores_svc = cross_validation.cross_val_score(svc,X, y_class, cv=10)\n",
    "    scores_svc5 = cross_validation.cross_val_score(svc,X, y_clf, cv=10)\n",
    "    \n",
    "    print \"clf\",np.mean(scores_clf)\n",
    "    print \"svr_lin\",np.mean(scores_svr_lin)\n",
    "    print \"svr_poly\",np.mean(scores_svr_poly)\n",
    "    print \"gnb\",np.mean(scores_gnb)\n",
    "    print \"svc\",np.mean(scores_svc)\n",
    "    print \"svc5\",np.mean(scores_svc)\n",
    "    print \"---------\"\n",
    "\n",
    "    joblib.dump(clf,\"clf\")\n",
    "    joblib.dump(gnb,\"gnb.pkl\", compress = 1)\n",
    "    print(\"ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "best = pd.read_csv(\"./best.csv\",sep=\";\", header=0,)\n",
    "sequence = pd.read_csv(\"./sequence.csv\",sep=\",\", header=0,)\n",
    "document = pd.read_csv(\"./document.csv\",sep=\",\",header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000        0.380687   0.335516         0.243740\n",
      "overallQuality   0.380687        1.000000   0.327871         0.792504\n",
      "sentiment        0.335516        0.327871   1.000000         0.270107\n",
      "trustworthiness  0.243740        0.792504   0.270107         1.000000\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000        0.190526   0.087722        -0.036742\n",
      "overallQuality   0.190526        1.000000   0.327871         0.792504\n",
      "sentiment        0.087722        0.327871   1.000000         0.270107\n",
      "trustworthiness -0.036742        0.792504   0.270107         1.000000\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000        0.213961   0.207660        -0.003837\n",
      "overallQuality   0.213961        1.000000   0.327871         0.792504\n",
      "sentiment        0.207660        0.327871   1.000000         0.270107\n",
      "trustworthiness -0.003837        0.792504   0.270107         1.000000\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000        0.253441   0.092705         0.282424\n",
      "overallQuality   0.253441        1.000000   0.327871         0.792504\n",
      "sentiment        0.092705        0.327871   1.000000         0.270107\n",
      "trustworthiness  0.282424        0.792504   0.270107         1.000000\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000        0.155691  -0.151507         0.166315\n",
      "overallQuality   0.155691        1.000000   0.327871         0.792504\n",
      "sentiment       -0.151507        0.327871   1.000000         0.270107\n",
      "trustworthiness  0.166315        0.792504   0.270107         1.000000\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000        0.235755   0.045484         0.410326\n",
      "overallQuality   0.235755        1.000000   0.327871         0.792504\n",
      "sentiment        0.045484        0.327871   1.000000         0.270107\n",
      "trustworthiness  0.410326        0.792504   0.270107         1.000000\n",
      "                 overallQuality  accuracy  completeness  neutrality  \\\n",
      "overallQuality         1.000000  0.889172      0.693068    0.448329   \n",
      "accuracy               0.889172  1.000000      0.765094    0.557197   \n",
      "completeness           0.693068  0.765094      1.000000    0.677823   \n",
      "neutrality             0.448329  0.557197      0.677823    1.000000   \n",
      "relevance              0.637525  0.611837      0.670059    0.301858   \n",
      "trustworthiness        0.783530  0.859017      0.699500    0.631610   \n",
      "readability            0.662217  0.672495      0.584226    0.374816   \n",
      "precision              0.761201  0.806734      0.767970    0.508070   \n",
      "\n",
      "                 relevance  trustworthiness  readability  precision  \n",
      "overallQuality    0.637525         0.783530     0.662217   0.761201  \n",
      "accuracy          0.611837         0.859017     0.672495   0.806734  \n",
      "completeness      0.670059         0.699500     0.584226   0.767970  \n",
      "neutrality        0.301858         0.631610     0.374816   0.508070  \n",
      "relevance         1.000000         0.531970     0.657459   0.694252  \n",
      "trustworthiness   0.531970         1.000000     0.650338   0.791763  \n",
      "readability       0.657459         0.650338     1.000000   0.622818  \n",
      "precision         0.694252         0.791763     0.622818   1.000000  \n"
     ]
    }
   ],
   "source": [
    "document = pd.read_csv(\"./document.csv\",sep=\";\",header=0)\n",
    "#print document \n",
    "k = [document.loc[document[\"_id\"] == \"ObjectId(%s)\" % x['$oid']]['url'] for y in sequence.loc[sequence['user'].notnull()]['sequence'].map(json.loads) for x in y]\n",
    "k1 = [x.tolist()[0] for x in k]\n",
    "\n",
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "t1 = ['entities','sentiment','trustworthiness','sources','titles','all']\n",
    "\n",
    "for t in t1:\n",
    "    k = [x.replace(\"[ \",\"['\").replace(\"]\",\"']\").replace(\", \",\"', '\") for x in best.loc[best['key'] == t]['articles'] if len(x)>0]\n",
    "    k = [ast.literal_eval(x) for x in k if x != \"[\\']\"]\n",
    "    n = Counter([x for y in k for x in y])\n",
    "    tot = Counter(k1)\n",
    "    frac = dict()\n",
    "    for v in n:\n",
    "        frac[v] = (n[v]+1)/(float(tot[v])+2)\n",
    "    frac = pd.Series(frac)\n",
    "    k = grouped_assessment['overallQuality']\n",
    "    k = pd.concat([frac, k,pd2['sentiment'],pd2['trustworthiness']], axis=1).fillna(value=0)\n",
    "    print k.loc[k['overallQuality']>0].corr(method=\"spearman\")\n",
    "    \n",
    "print grouped_assessment.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "clf 0.235119047619\n",
      "svr_lin -0.173164792129\n",
      "svr_poly -0.167237861336\n",
      "gnb 0.547619047619\n",
      "svc 0.716666666667\n",
      "svc5 0.541071428571\n",
      "---------\n",
      "emotions\n",
      "clf 0.420238095238\n",
      "svr_lin -2.16605192787\n",
      "svr_poly -1.3294218416\n",
      "gnb 0.235119047619\n",
      "svc 0.658333333333\n",
      "svc5 0.225\n",
      "---------\n",
      "trustworthiness\n",
      "clf 0.372023809524\n",
      "svr_lin 0.292045594174\n",
      "svr_poly 0.224336370237\n",
      "gnb 0.430357142857\n",
      "svc 0.891666666667\n",
      "svc5 0.630357142857\n",
      "---------\n",
      "entities\n",
      "clf 0.249404761905\n",
      "svr_lin -2.14454946934\n",
      "svr_poly -0.78663958005\n",
      "gnb 0.318452380952\n",
      "svc 0.6\n",
      "svc5 0.177976190476\n",
      "---------\n",
      "sentiment, emotions\n",
      "clf 0.285119047619\n",
      "svr_lin -0.857418381768\n",
      "svr_poly -0.970288885471\n",
      "gnb 0.208333333333\n",
      "svc 0.725\n",
      "svc5 0.175\n",
      "---------\n",
      "sentiment, trustworthiness\n",
      "clf 0.266071428571\n",
      "svr_lin 0.273024728409\n",
      "svr_poly 0.191857341585\n",
      "gnb 0.503571428571\n",
      "svc 0.866666666667\n",
      "svc5 0.528571428571\n",
      "---------\n",
      "sentiment, entities\n",
      "clf 0.274404761905\n",
      "svr_lin -2.14638260929\n",
      "svr_poly -0.788453677416\n",
      "gnb 0.318452380952\n",
      "svc 0.6\n",
      "svc5 0.177976190476\n",
      "---------\n",
      "emotions, trustworthiness\n",
      "clf 0.341071428571\n",
      "svr_lin 0.209612921852\n",
      "svr_poly 0.269474523728\n",
      "gnb 0.380952380952\n",
      "svc 0.866666666667\n",
      "svc5 0.264285714286\n",
      "---------\n",
      "emotions, entities\n",
      "clf 0.21369047619\n",
      "svr_lin -2.43320720745\n",
      "svr_poly -0.79587100123\n",
      "gnb 0.318452380952\n",
      "svc 0.575\n",
      "svc5 0.202976190476\n",
      "---------\n",
      "trustworthiness, entities\n",
      "clf 0.405357142857\n",
      "svr_lin -0.184262372419\n",
      "svr_poly -0.0646165781127\n",
      "gnb 0.318452380952\n",
      "svc 0.85\n",
      "svc5 0.342261904762\n",
      "---------\n",
      "sentiment, emotions, trustworthiness\n",
      "clf 0.332738095238\n",
      "svr_lin 0.147853775477\n",
      "svr_poly 0.0341708904259\n",
      "gnb 0.368452380952\n",
      "svc 0.841666666667\n",
      "svc5 0.289285714286\n",
      "---------\n",
      "sentiment, emotions, entities\n",
      "clf 0.33869047619\n",
      "svr_lin -2.43417684493\n",
      "svr_poly -0.79718773221\n",
      "gnb 0.318452380952\n",
      "svc 0.575\n",
      "svc5 0.202976190476\n",
      "---------\n",
      "sentiment, trustworthiness, entities\n",
      "clf 0.347023809524\n",
      "svr_lin -0.207180967532\n",
      "svr_poly -0.0639003227399\n",
      "gnb 0.318452380952\n",
      "svc 0.85\n",
      "svc5 0.342261904762\n",
      "---------\n",
      "emotions, trustworthiness, entities\n",
      "clf 0.472023809524\n",
      "svr_lin -0.228860159239\n",
      "svr_poly -0.0667960924292\n",
      "gnb 0.318452380952\n",
      "svc 0.85\n",
      "svc5 0.342261904762\n",
      "---------\n",
      "sentiment, emotions, trustworthiness, entities\n",
      "clf 0.41130952381\n",
      "svr_lin -0.251515097147\n",
      "svr_poly -0.0662406150945\n",
      "gnb 0.318452380952\n",
      "svc 0.85\n",
      "svc5 0.342261904762\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVR, SVC\n",
    "\n",
    "dimensions = [\"sentiment\",\"Y\",\"trustworthiness\",\"X\"]\n",
    "emotions = [\"emotion.joy\",\"emotion.fear\",\"emotion.anger\",\"emotion.disgust\",\"emotion.sadness\"]\n",
    "import itertools\n",
    "for i in range(1,len(dimensions)+1):\n",
    "    j = [list(x) for x in list(itertools.combinations(dimensions,i))]\n",
    "    for feat in j:\n",
    "        print (', ').join(feat).replace(\"X\",\"entities\").replace(\"Y\",\"emotions\")\n",
    "        if (\"X\" in feat):\n",
    "            feat = [x for x in feat if x != \"X\"]\n",
    "            feat = feat + ent\n",
    "        if (\"Y\" in feat):\n",
    "            feat = [x for x in feat if x != \"Y\"]\n",
    "            feat = feat + emotions\n",
    "        X = pd2[feat]\n",
    "        y_clf = np.asarray(pd2['overallQuality'], dtype=\"|S6\")\n",
    "        y_gnb = np.asarray(pd2['overallQuality'], dtype=\"|S6\")\n",
    "        y_svr_lin = np.asarray(pd2['overallQuality'])\n",
    "        y_svr_poly = np.asarray(pd2['overallQuality'])\n",
    "        y_class = np.asarray([0 if x<=3 else 1 for x in pd2['overallQuality']])\n",
    "        clf = SGDClassifier(alpha=0.00005, n_iter=1000)\n",
    "        svr_lin = SVR(kernel='linear', C=1e3)\n",
    "        svr_poly = SVR(kernel='poly', C=1e3, degree=2)\n",
    "        gnb = GaussianNB()\n",
    "        svc = SVC(kernel='linear', C=1e3)\n",
    "        #clf.fit(X, y_clf)\n",
    "        #svr_lin.fit(X, y_svr_lin)\n",
    "        #svr_poly.fit(X, y_svr_poly)\n",
    "        #gnb.fit(X, y_gnb)\n",
    "        \n",
    "        scores_clf = cross_validation.cross_val_score(clf, X, y_clf, cv=10)\n",
    "        scores_svr_lin = cross_validation.cross_val_score(svr_lin, X, y_svr_lin, cv=10)\n",
    "        scores_svr_poly = cross_validation.cross_val_score(svr_poly, X, y_svr_poly, cv=10)\n",
    "        scores_gnb = cross_validation.cross_val_score(gnb, X, y_gnb, cv=10)\n",
    "        scores_svc = cross_validation.cross_val_score(svc,X, y_class, cv=10)\n",
    "        scores_svc5 = cross_validation.cross_val_score(svc,X, y_clf, cv=10)\n",
    "        print \"clf\",np.mean(scores_clf)\n",
    "        print \"svr_lin\",np.mean(scores_svr_lin)\n",
    "        print \"svr_poly\",np.mean(scores_svr_poly)\n",
    "        print \"gnb\",np.mean(scores_gnb)\n",
    "        print \"svc\",np.mean(scores_svc)\n",
    "        print \"svc5\",np.mean(scores_svc5)\n",
    "        print \"---------\"      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trustworthiness']\n"
     ]
    }
   ],
   "source": [
    "print [x for x in feat if x not in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 13] Permission denied: '/feats1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8a5f28d75551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/feats1.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'overallQuality'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dceolin/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal, **kwds)\u001b[0m\n\u001b[1;32m   1342\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1344\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dceolin/anaconda/lib/python2.7/site-packages/pandas/formats/format.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1524\u001b[0m             f = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m   1525\u001b[0m                             \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1526\u001b[0;31m                             compression=self.compression)\n\u001b[0m\u001b[1;32m   1527\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dceolin/anaconda/lib/python2.7/site-packages/pandas/io/common.pyc\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path, mode, encoding, compression)\u001b[0m\n\u001b[1;32m    424\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 13] Permission denied: '/feats1.csv'"
     ]
    }
   ],
   "source": [
    "#import documents\n",
    "#import assessments\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.externals import joblib\n",
    "import csv\n",
    "\n",
    "gnb = GaussianNB()\n",
    "pd.options.mode.chained_assignment = None \n",
    "ent = []\n",
    "\n",
    "pd2 = pd.read_csv(\"~/document.csv\",quotechar=\"\\\"\",sep=\",\",header=0)\n",
    "for i in range(0,50):\n",
    "    for x in json.loads(pd2.iloc[i].entities):\n",
    "        colname = x['disambiguated']['dbpedia'] if 'disambiguated' in x and 'dbpedia' in x['disambiguated'] else x['text']\n",
    "        pd2[colname] = np.zeros(50)\n",
    "        ent.append(colname)\n",
    "for i in range(0,50):\n",
    "    for x in json.loads(pd2.iloc[i].entities):\n",
    "        colname = x['disambiguated']['dbpedia'] if 'disambiguated' in x and 'dbpedia' in x['disambiguated'] else x['text']\n",
    "        pd2[colname][i] = float(x['relevance'])\n",
    "\n",
    "#print pd2\n",
    "\n",
    "assessments = pd.read_csv(\"./ass_j.csv\",sep=\",\", header=0,)\n",
    "\n",
    "grouped_assessment = assessments.groupby('target').mean()#['overallQuality']\n",
    " \n",
    "x = [x for x in pd2['url'] if x in assessments['target']]\n",
    "pd3 = pd2.merge(assessments,how=\"outer\",left_on='url', right_on='target' )\n",
    "pd2 = pd2.set_index('url')\n",
    "\n",
    "pd2 = pd.concat([pd2, grouped_assessment], axis=1, join='inner')\n",
    "\n",
    "\n",
    "l = [x for x in list(pd2.columns.values) if x not in list(assessments.columns.values)]\n",
    "l = [x for x in l if x not in ['entities','title','source','_id']]\n",
    "#print pd2.columns.values\n",
    "X = pd2[l]\n",
    "X2 = pd3[l]\n",
    "X.to_csv('/feats.csv', sep=\";\")\n",
    "y = np.asarray(pd2['overallQuality'])\n",
    "\n",
    "#X = pd2[x for x in list(pd2.columns.values) if x not in list(assessments.columns.values)]\n",
    "for x in ['overallQuality']:\n",
    "    y_clf = np.asarray(pd2[x], dtype=\"|S6\")\n",
    "    y_gnb = np.asarray(pd2[x], dtype=\"|S6\")\n",
    "    y_svr_lin = np.asarray(pd2[x])\n",
    "    y_svr_poly = np.asarray(pd2[x])\n",
    "    y_class = np.asarray([0 if x<=3 else 1 for x in pd3['overallQuality']])\n",
    "    clf = SGDClassifier(alpha=0.00005, n_iter=1000)\n",
    "    svr_lin = SVR(kernel='linear', C=1e3)\n",
    "    svr_poly = SVR(kernel='poly', C=1e3, degree=2)\n",
    "    gnb = GaussianNB()\n",
    "    svc = SVC(kernel='linear', C=1e3)\n",
    "    clf.fit(X, y_clf)\n",
    "    joblib.dump(clf,'clf.pkl')\n",
    "    '''svr_lin.fit(X, y_svr_lin)\n",
    "    svr_poly.fit(X, y_svr_poly)\n",
    "    gnb.fit(X, y_gnb)\n",
    "    print X.shape'''\n",
    "    \n",
    "    scores_clf = cross_validation.cross_val_score(clf, X, y_clf, cv=10)\n",
    "    scores_svr_lin = cross_validation.cross_val_score(svr_lin, X, y_svr_lin, cv=10)\n",
    "    scores_svr_poly = cross_validation.cross_val_score(svr_poly, X, y_svr_poly, cv=10)\n",
    "    scores_gnb = cross_validation.cross_val_score(gnb, X, y_gnb, cv=10)\n",
    "    scores_all_svc5 = cross_validation.cross_val_score(svc, X2, np.asarray(pd3[x], dtype=\"|S6\"), cv=10)\n",
    "    scores_svc = cross_validation.cross_val_score(svc,X2, y_class, cv=10)\n",
    "    print \"clf\",np.mean(scores_clf)\n",
    "    print \"svr_lin\",np.mean(scores_svr_lin)\n",
    "    print \"svr_poly\",np.mean(scores_svr_poly)\n",
    "    print \"gnb\",np.mean(scores_gnb)\n",
    "    print \"svc2_all\",np.mean(scores_svc)\n",
    "    print \"svc5_all\",np.mean(scores_all_svc5)\n",
    "    print \"---------\"\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "clf 0.0819444444444\n",
      "svr_lin -0.233241348516\n",
      "svr_poly -0.285108917838\n",
      "gnb 0.2625\n",
      "svc2_all 0.548484848485\n",
      "svc5_all 0.297724497724\n",
      "---------\n",
      "emotions\n",
      "clf 0.0644444444444\n",
      "svr_lin -0.563215981807\n",
      "svr_poly -0.870505737047\n",
      "gnb 0.125555555556\n",
      "svc2_all 0.451515151515\n",
      "svc5_all 0.318018093018\n",
      "---------\n",
      "trustworthiness\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['trustworthiness'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3a8866d36670>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0memotions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0my_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpd3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'overallQuality'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0my_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'overallQuality'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"|S6\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dceolin/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1989\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1990\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1991\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1992\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1993\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dceolin/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2033\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2034\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2035\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2036\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dceolin/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1212\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['trustworthiness'] not in index\""
     ]
    }
   ],
   "source": [
    "dimensions = [\"sentiment\",\"Y\",\"trustworthiness\",\"X\"]\n",
    "emotions = [\"emotion.joy\",\"emotion.fear\",\"emotion.anger\",\"emotion.disgust\",\"emotion.sadness\"]\n",
    "import itertools\n",
    "for i in range(1,len(dimensions)+1):\n",
    "    j = [list(x) for x in list(itertools.combinations(dimensions,i))]\n",
    "    for feat in j:\n",
    "        print (', ').join(feat).replace(\"X\",\"entities\").replace(\"Y\",\"emotions\")\n",
    "        if (\"X\" in feat):\n",
    "            feat = [x for x in feat if x != \"X\"]\n",
    "            feat = feat + ent\n",
    "        if (\"Y\" in feat):\n",
    "            feat = [x for x in feat if x != \"Y\"]\n",
    "            feat = feat + emotions\n",
    "        X = pd2[feat]\n",
    "        X2 = pd3[feat]\n",
    "        y_class = np.asarray([0 if x<=3 else 1 for x in pd3['overallQuality']])\n",
    "        y_clf = np.asarray(pd2['overallQuality'], dtype=\"|S6\")\n",
    "        y_gnb = np.asarray(pd2['overallQuality'], dtype=\"|S6\")\n",
    "        y_svr_lin = np.asarray(pd2['overallQuality'])\n",
    "        y_svr_poly = np.asarray(pd2['overallQuality'])\n",
    "        clf = SGDClassifier(alpha=0.00005, n_iter=1000)\n",
    "        svr_lin = SVR(kernel='linear', C=1e3)\n",
    "        svr_poly = SVR(kernel='poly', C=1e3, degree=2)\n",
    "        gnb = GaussianNB()\n",
    "        clf.fit(X, y_clf)\n",
    "        svr_lin.fit(X, y_svr_lin)\n",
    "        svr_poly.fit(X, y_svr_poly)\n",
    "        gnb.fit(X, y_gnb)\n",
    "        \n",
    "        scores_clf = cross_validation.cross_val_score(clf, X, y_clf, cv=10)\n",
    "        scores_svr_lin = cross_validation.cross_val_score(svr_lin, X, y_svr_lin, cv=10)\n",
    "        scores_svr_poly = cross_validation.cross_val_score(svr_poly, X, y_svr_poly, cv=10)\n",
    "        scores_gnb = cross_validation.cross_val_score(gnb, X, y_gnb, cv=10)\n",
    "        scores_all_svc5 = cross_validation.cross_val_score(svc, X2, np.asarray(pd3['overallQuality'], dtype=\"|S6\"), cv=10)\n",
    "        scores_svc = cross_validation.cross_val_score(svc,X2, y_class, cv=10)\n",
    "        \n",
    "        print \"clf\",np.mean(scores_clf)\n",
    "        print \"svr_lin\",np.mean(scores_svr_lin)\n",
    "        print \"svr_poly\",np.mean(scores_svr_poly)\n",
    "        print \"gnb\",np.mean(scores_gnb)\n",
    "        print \"svc2_all\",np.mean(scores_svc)\n",
    "        print \"svc5_all\",np.mean(scores_all_svc5)\n",
    "        print \"---------\"      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000       -0.068923  -0.161310        -0.012232\n",
      "overallQuality  -0.068923        1.000000   0.306377         0.814028\n",
      "sentiment       -0.161310        0.306377   1.000000         0.280143\n",
      "trustworthiness -0.012232        0.814028   0.280143         1.000000\n",
      "sentiment\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000        0.093340   0.121328         0.171270\n",
      "overallQuality   0.093340        1.000000   0.306377         0.814028\n",
      "sentiment        0.121328        0.306377   1.000000         0.280143\n",
      "trustworthiness  0.171270        0.814028   0.280143         1.000000\n",
      "trustworthiness\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000        0.199459   0.192893         0.217135\n",
      "overallQuality   0.199459        1.000000   0.306377         0.814028\n",
      "sentiment        0.192893        0.306377   1.000000         0.280143\n",
      "trustworthiness  0.217135        0.814028   0.280143         1.000000\n",
      "sources\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000        0.290637   0.090771         0.450985\n",
      "overallQuality   0.290637        1.000000   0.306377         0.814028\n",
      "sentiment        0.090771        0.306377   1.000000         0.280143\n",
      "trustworthiness  0.450985        0.814028   0.280143         1.000000\n",
      "titles\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000       -0.068607  -0.072244         0.081726\n",
      "overallQuality  -0.068607        1.000000   0.306377         0.814028\n",
      "sentiment       -0.072244        0.306377   1.000000         0.280143\n",
      "trustworthiness  0.081726        0.814028   0.280143         1.000000\n",
      "all\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000        0.203443   0.157513         0.156431\n",
      "overallQuality   0.203443        1.000000   0.306377         0.814028\n",
      "sentiment        0.157513        0.306377   1.000000         0.280143\n",
      "trustworthiness  0.156431        0.814028   0.280143         1.000000\n",
      "                 overallQuality  accuracy  completeness  neutrality  \\\n",
      "overallQuality         1.000000  0.889662      0.694396    0.461334   \n",
      "accuracy               0.889662  1.000000      0.765922    0.568996   \n",
      "completeness           0.694396  0.765922      1.000000    0.701420   \n",
      "neutrality             0.461334  0.568996      0.701420    1.000000   \n",
      "relevance              0.634596  0.608054      0.654732    0.311987   \n",
      "trustworthiness        0.804964  0.881774      0.725162    0.618599   \n",
      "readability            0.667052  0.677106      0.578546    0.403131   \n",
      "precision              0.768356  0.814074      0.775485    0.493895   \n",
      "\n",
      "                 relevance  trustworthiness  readability  precision  \n",
      "overallQuality    0.634596         0.804964     0.667052   0.768356  \n",
      "accuracy          0.608054         0.881774     0.677106   0.814074  \n",
      "completeness      0.654732         0.725162     0.578546   0.775485  \n",
      "neutrality        0.311987         0.618599     0.403131   0.493895  \n",
      "relevance         1.000000         0.578497     0.644123   0.724098  \n",
      "trustworthiness   0.578497         1.000000     0.711564   0.790643  \n",
      "readability       0.644123         0.711564     1.000000   0.658378  \n",
      "precision         0.724098         0.790643     0.658378   1.000000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "document = pd.read_csv(\"./document.csv\",sep=\";\",header=0)\n",
    "best = pd.read_csv(\"./best_j.csv\",sep=\";\", header=0,)\n",
    "sequence = pd.read_csv(\"./sequence_old.csv\",sep=\",\", header=0,)\n",
    "\n",
    "#print document \n",
    "k = [document.loc[document[\"_id\"] == \"ObjectId(%s)\" % x['$oid']]['url'] for y in sequence.loc[sequence['user'].notnull()]['sequence'].map(json.loads) for x in y]\n",
    "k1 = [x.tolist()[0] for x in k]\n",
    "\n",
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "t1 = ['entities','sentiment','trustworthiness','sources','titles','all']\n",
    "\n",
    "for t in t1:\n",
    "    k = [x.replace(\"[ \",\"['\").replace(\"]\",\"']\").replace(\", \",\"', '\") for x in best.loc[best['key'] == t]['articles'] if len(x)>0]\n",
    "    k = [ast.literal_eval(x) for x in k if x != \"[\\']\"]\n",
    "    n = Counter([x for y in k for x in y])\n",
    "    tot = Counter(k1)\n",
    "    frac = dict()\n",
    "    for v in n:\n",
    "        frac[v] = (n[v]+1)/(float(tot[v])+2)\n",
    "    frac = pd.Series(frac)\n",
    "    k = grouped_assessment['overallQuality']\n",
    "    k = pd.concat([frac, k,pd2['sentiment'],pd2['trustworthiness']], axis=1).fillna(value=0)\n",
    "    print t\n",
    "    print k.loc[k['overallQuality']>0].corr(method=\"spearman\")\n",
    "    \n",
    "print grouped_assessment.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0656689436349\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "dataSetI = [3, 45, 7, 2]\n",
    "dataSetII = [1, 0, 0, 0]\n",
    "result = 1 - spatial.distance.cosine(dataSetI, dataSetII)\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class SVRClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y):\n",
    "        self.classes_, indices = np.unique([\"Low\", \"Medium\", \"High\"],return_inverse=True)\n",
    "        self.majority_ = np.argmax(np.bincount(indices))\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return np.repeat(self.classes_[self.majority_], len(X))\n",
    "    def get_params(self, deep=True):\n",
    "    # suppose this estimator has parameters \"alpha\" and \"recursive\"\n",
    "        return {}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['High' 'Low' 'Medium']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print np.unique([\"Low\", \"Medium\", \"High\"],return_inverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n"
     ]
    }
   ],
   "source": [
    "print len(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WilcoxonResult(statistic=1327.5, pvalue=0.74254178143127447)\n",
      "WilcoxonResult(statistic=1147.0, pvalue=0.43987293045456055)\n",
      "WilcoxonResult(statistic=1295.0, pvalue=0.61210094341467913)\n",
      "WilcoxonResult(statistic=1317.0, pvalue=0.8514552818301987)\n",
      "WilcoxonResult(statistic=1174.5, pvalue=0.54677037468270062)\n",
      "WilcoxonResult(statistic=1224.0, pvalue=0.48080552392505227)\n",
      "WilcoxonResult(statistic=1445.0, pvalue=0.62881760981350787)\n",
      "WilcoxonResult(statistic=1270.0, pvalue=0.96275276314126446)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats \n",
    "assessments = pd.read_csv(\"./ass_j2.csv\",sep=\";\", header=0,)\n",
    "new_assessments = pd.read_csv(\"./new_ass_j.csv\",sep=\";\", header=0,)\n",
    "x = ['overallQuality','accuracy','completeness','neutrality','relevance','trustworthiness','readability','precision']\n",
    "\n",
    "for y in x:\n",
    "    print stats.wilcoxon(assessments[y],new_assessments[y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "34\n",
      "WilcoxonResult(statistic=180.5, pvalue=0.60359714676788101)\n",
      "WilcoxonResult(statistic=165.5, pvalue=0.79655991284515926)\n",
      "WilcoxonResult(statistic=220.5, pvalue=0.80165247020251607)\n",
      "WilcoxonResult(statistic=47.5, pvalue=0.7515290794442091)\n",
      "WilcoxonResult(statistic=168.0, pvalue=0.84764952504786217)\n",
      "WilcoxonResult(statistic=214.0, pvalue=0.69948630563063308)\n",
      "WilcoxonResult(statistic=246.5, pvalue=0.97632365735640358)\n",
      "WilcoxonResult(statistic=196.0, pvalue=0.87150716860569322)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "assessments = pd.read_csv(\"./data3.csv\",sep=\";\", header=0,)\n",
    "new_assessments = pd.read_csv(\"./new_ass.csv\",sep=\";\", header=0,)\n",
    "assessments = assessments.loc[assessments['target'].isin(new_assessments['target']),:]\n",
    "#new_assessments = new_assessments.loc[new_assessments['target'] in assessments['target'],:]\n",
    "                                  #df1.loc[:, df1.loc['a'] > 0]\n",
    "print len(assessments)\n",
    "print len(new_assessments)\n",
    "\n",
    "x = ['overallQuality','accuracy','completeness','neutrality','relevance','trustworthiness','readability','precision']\n",
    "\n",
    "for y in x:\n",
    "    print stats.wilcoxon(assessments[y],new_assessments[y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=2.5, pvalue=0.092591595750229932)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.wilcoxon([75,78,72,72],[89,86,85,85])\n",
    "stats.wilcoxon([63,53,34,34],[48,46,38,39])\n",
    "stats.wilcoxon([89,69,46,63,80,67,77],[89,69,45,64,78,67,76])\n",
    "stats.wilcoxon([-7,9,20,29,-7,20],[38,19,21,25,15,24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
