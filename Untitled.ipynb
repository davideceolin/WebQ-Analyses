{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.zeros(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf 0.270238095238\n",
      "svr_lin -1.12762051095\n",
      "svr_poly -0.294695497912\n",
      "gnb 0.329166666667\n",
      "svc 0.653333333333\n",
      "svc5 0.653333333333\n",
      "---------\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "#import documents\n",
    "#import assessments\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVR, SVC\n",
    "import csv \n",
    "from sklearn.externals import joblib\n",
    "\n",
    "gnb = GaussianNB()\n",
    "pd.options.mode.chained_assignment = None \n",
    "ent = []\n",
    "\n",
    "pd2 = pd.read_csv(\"~/document.csv\",quotechar=\"\\\"\",sep=\";\",header=0)\n",
    "for i in range(0,50):\n",
    "    for x in json.loads(pd2.iloc[i].entities):\n",
    "        colname = x['disambiguated']['dbpedia'] if 'disambiguated' in x and 'dbpedia' in x['disambiguated'] else x['text']\n",
    "        pd2[colname] = np.zeros(50)\n",
    "        ent.append(colname)\n",
    "for i in range(0,50):\n",
    "    for x in json.loads(pd2.iloc[i].entities):\n",
    "        colname = x['disambiguated']['dbpedia'] if 'disambiguated' in x and 'dbpedia' in x['disambiguated'] else x['text']\n",
    "        pd2[colname][i] = float(x['relevance'])\n",
    "\n",
    "#print pd2\n",
    "\n",
    "assessments = pd.read_csv(\"./data2.csv\",sep=\";\", header=0,)\n",
    "\n",
    "grouped_assessment = assessments.groupby('target').mean()#['overallQuality']\n",
    "pd2 = pd2.set_index('url')\n",
    "\n",
    "pd2 = pd.concat([pd2, grouped_assessment], axis=1, join='inner')\n",
    "\n",
    "l = [x for x in list(pd2.columns.values) if x not in list(assessments.columns.values)]\n",
    "l = [x for x in l if x not in ['entities','title','source','_id']]\n",
    "l2 = [x.encode(\"utf-8\") for x in l]\n",
    "with open('feats.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(l2)\n",
    "#print pd2.columns.values\n",
    "X = pd2[l]\n",
    "y = np.asarray(pd2['overallQuality'])\n",
    "#X = pd2[x for x in list(pd2.columns.values) if x not in list(assessments.columns.values)]\n",
    "for x in ['overallQuality']:\n",
    "    y_clf = np.asarray(pd2[x], dtype=\"|S6\")\n",
    "    y_gnb = np.asarray(pd2[x], dtype=\"|S6\")\n",
    "    y_svr_lin = np.asarray(pd2[x])\n",
    "    y_svr_poly = np.asarray(pd2[x])\n",
    "    y_class = np.asarray([0 if x<=1 else 2 if x==5 else 1 for x in pd2[x]])\n",
    "    clf = SGDClassifier(alpha=0.00005, n_iter=1000)\n",
    "    svr_lin = SVR(kernel='linear', C=1e3)\n",
    "    svr_poly = SVR(kernel='poly', C=1e3, degree=2)\n",
    "    gnb = GaussianNB()\n",
    "    svc = SVC(kernel='linear', C=1e3)\n",
    "    clf.fit(X, y_clf)\n",
    "    svr_lin.fit(X, y_svr_lin)\n",
    "    svr_poly.fit(X, y_svr_poly)\n",
    "    gnb.fit(X, y_gnb)\n",
    "    #svc.fit(X, y_svc)\n",
    "    \n",
    "    scores_clf = cross_validation.cross_val_score(clf, X, y_clf, cv=10)\n",
    "    scores_svr_lin = cross_validation.cross_val_score(svr_lin, X, y_svr_lin, cv=10)\n",
    "    scores_svr_poly = cross_validation.cross_val_score(svr_poly, X, y_svr_poly, cv=10)\n",
    "    scores_gnb = cross_validation.cross_val_score(gnb, X, y_gnb, cv=10)\n",
    "    scores_svc = cross_validation.cross_val_score(svc,X, y_class, cv=10)\n",
    "    scores_svc5 = cross_validation.cross_val_score(svc,X, y_clf, cv=10)\n",
    "    \n",
    "    print \"clf\",np.mean(scores_clf)\n",
    "    print \"svr_lin\",np.mean(scores_svr_lin)\n",
    "    print \"svr_poly\",np.mean(scores_svr_poly)\n",
    "    print \"gnb\",np.mean(scores_gnb)\n",
    "    print \"svc\",np.mean(scores_svc)\n",
    "    print \"svc5\",np.mean(scores_svc)\n",
    "    print \"---------\"\n",
    "\n",
    "    joblib.dump(clf,\"clf\")\n",
    "    joblib.dump(gnb,\"gnb.pkl\", compress = 1)\n",
    "    print(\"ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "best = pd.read_csv(\"./best.csv\",sep=\";\", header=0,)\n",
    "sequence = pd.read_csv(\"./sequence.csv\",sep=\",\", header=0,)\n",
    "document = pd.read_csv(\"./document.csv\",sep=\",\",header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000        0.380687   0.335516         0.243740\n",
      "overallQuality   0.380687        1.000000   0.327871         0.792504\n",
      "sentiment        0.335516        0.327871   1.000000         0.270107\n",
      "trustworthiness  0.243740        0.792504   0.270107         1.000000\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000        0.190526   0.087722        -0.036742\n",
      "overallQuality   0.190526        1.000000   0.327871         0.792504\n",
      "sentiment        0.087722        0.327871   1.000000         0.270107\n",
      "trustworthiness -0.036742        0.792504   0.270107         1.000000\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000        0.213961   0.207660        -0.003837\n",
      "overallQuality   0.213961        1.000000   0.327871         0.792504\n",
      "sentiment        0.207660        0.327871   1.000000         0.270107\n",
      "trustworthiness -0.003837        0.792504   0.270107         1.000000\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000        0.253441   0.092705         0.282424\n",
      "overallQuality   0.253441        1.000000   0.327871         0.792504\n",
      "sentiment        0.092705        0.327871   1.000000         0.270107\n",
      "trustworthiness  0.282424        0.792504   0.270107         1.000000\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000        0.155691  -0.151507         0.166315\n",
      "overallQuality   0.155691        1.000000   0.327871         0.792504\n",
      "sentiment       -0.151507        0.327871   1.000000         0.270107\n",
      "trustworthiness  0.166315        0.792504   0.270107         1.000000\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000        0.235755   0.045484         0.410326\n",
      "overallQuality   0.235755        1.000000   0.327871         0.792504\n",
      "sentiment        0.045484        0.327871   1.000000         0.270107\n",
      "trustworthiness  0.410326        0.792504   0.270107         1.000000\n",
      "                 overallQuality  accuracy  completeness  neutrality  \\\n",
      "overallQuality         1.000000  0.889172      0.693068    0.448329   \n",
      "accuracy               0.889172  1.000000      0.765094    0.557197   \n",
      "completeness           0.693068  0.765094      1.000000    0.677823   \n",
      "neutrality             0.448329  0.557197      0.677823    1.000000   \n",
      "relevance              0.637525  0.611837      0.670059    0.301858   \n",
      "trustworthiness        0.783530  0.859017      0.699500    0.631610   \n",
      "readability            0.662217  0.672495      0.584226    0.374816   \n",
      "precision              0.761201  0.806734      0.767970    0.508070   \n",
      "\n",
      "                 relevance  trustworthiness  readability  precision  \n",
      "overallQuality    0.637525         0.783530     0.662217   0.761201  \n",
      "accuracy          0.611837         0.859017     0.672495   0.806734  \n",
      "completeness      0.670059         0.699500     0.584226   0.767970  \n",
      "neutrality        0.301858         0.631610     0.374816   0.508070  \n",
      "relevance         1.000000         0.531970     0.657459   0.694252  \n",
      "trustworthiness   0.531970         1.000000     0.650338   0.791763  \n",
      "readability       0.657459         0.650338     1.000000   0.622818  \n",
      "precision         0.694252         0.791763     0.622818   1.000000  \n"
     ]
    }
   ],
   "source": [
    "document = pd.read_csv(\"./document.csv\",sep=\";\",header=0)\n",
    "#print document \n",
    "k = [document.loc[document[\"_id\"] == \"ObjectId(%s)\" % x['$oid']]['url'] for y in sequence.loc[sequence['user'].notnull()]['sequence'].map(json.loads) for x in y]\n",
    "k1 = [x.tolist()[0] for x in k]\n",
    "\n",
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "t1 = ['entities','sentiment','trustworthiness','sources','titles','all']\n",
    "\n",
    "for t in t1:\n",
    "    k = [x.replace(\"[ \",\"['\").replace(\"]\",\"']\").replace(\", \",\"', '\") for x in best.loc[best['key'] == t]['articles'] if len(x)>0]\n",
    "    k = [ast.literal_eval(x) for x in k if x != \"[\\']\"]\n",
    "    n = Counter([x for y in k for x in y])\n",
    "    tot = Counter(k1)\n",
    "    frac = dict()\n",
    "    for v in n:\n",
    "        frac[v] = (n[v]+1)/(float(tot[v])+2)\n",
    "    frac = pd.Series(frac)\n",
    "    k = grouped_assessment['overallQuality']\n",
    "    k = pd.concat([frac, k,pd2['sentiment'],pd2['trustworthiness']], axis=1).fillna(value=0)\n",
    "    print k.loc[k['overallQuality']>0].corr(method=\"spearman\")\n",
    "    \n",
    "print grouped_assessment.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "clf 0.235119047619\n",
      "svr_lin -0.173164792129\n",
      "svr_poly -0.167237861336\n",
      "gnb 0.547619047619\n",
      "svc 0.716666666667\n",
      "svc5 0.541071428571\n",
      "---------\n",
      "emotions\n",
      "clf 0.420238095238\n",
      "svr_lin -2.16605192787\n",
      "svr_poly -1.3294218416\n",
      "gnb 0.235119047619\n",
      "svc 0.658333333333\n",
      "svc5 0.225\n",
      "---------\n",
      "trustworthiness\n",
      "clf 0.372023809524\n",
      "svr_lin 0.292045594174\n",
      "svr_poly 0.224336370237\n",
      "gnb 0.430357142857\n",
      "svc 0.891666666667\n",
      "svc5 0.630357142857\n",
      "---------\n",
      "entities\n",
      "clf 0.249404761905\n",
      "svr_lin -2.14454946934\n",
      "svr_poly -0.78663958005\n",
      "gnb 0.318452380952\n",
      "svc 0.6\n",
      "svc5 0.177976190476\n",
      "---------\n",
      "sentiment, emotions\n",
      "clf 0.285119047619\n",
      "svr_lin -0.857418381768\n",
      "svr_poly -0.970288885471\n",
      "gnb 0.208333333333\n",
      "svc 0.725\n",
      "svc5 0.175\n",
      "---------\n",
      "sentiment, trustworthiness\n",
      "clf 0.266071428571\n",
      "svr_lin 0.273024728409\n",
      "svr_poly 0.191857341585\n",
      "gnb 0.503571428571\n",
      "svc 0.866666666667\n",
      "svc5 0.528571428571\n",
      "---------\n",
      "sentiment, entities\n",
      "clf 0.274404761905\n",
      "svr_lin -2.14638260929\n",
      "svr_poly -0.788453677416\n",
      "gnb 0.318452380952\n",
      "svc 0.6\n",
      "svc5 0.177976190476\n",
      "---------\n",
      "emotions, trustworthiness\n",
      "clf 0.341071428571\n",
      "svr_lin 0.209612921852\n",
      "svr_poly 0.269474523728\n",
      "gnb 0.380952380952\n",
      "svc 0.866666666667\n",
      "svc5 0.264285714286\n",
      "---------\n",
      "emotions, entities\n",
      "clf 0.21369047619\n",
      "svr_lin -2.43320720745\n",
      "svr_poly -0.79587100123\n",
      "gnb 0.318452380952\n",
      "svc 0.575\n",
      "svc5 0.202976190476\n",
      "---------\n",
      "trustworthiness, entities\n",
      "clf 0.405357142857\n",
      "svr_lin -0.184262372419\n",
      "svr_poly -0.0646165781127\n",
      "gnb 0.318452380952\n",
      "svc 0.85\n",
      "svc5 0.342261904762\n",
      "---------\n",
      "sentiment, emotions, trustworthiness\n",
      "clf 0.332738095238\n",
      "svr_lin 0.147853775477\n",
      "svr_poly 0.0341708904259\n",
      "gnb 0.368452380952\n",
      "svc 0.841666666667\n",
      "svc5 0.289285714286\n",
      "---------\n",
      "sentiment, emotions, entities\n",
      "clf 0.33869047619\n",
      "svr_lin -2.43417684493\n",
      "svr_poly -0.79718773221\n",
      "gnb 0.318452380952\n",
      "svc 0.575\n",
      "svc5 0.202976190476\n",
      "---------\n",
      "sentiment, trustworthiness, entities\n",
      "clf 0.347023809524\n",
      "svr_lin -0.207180967532\n",
      "svr_poly -0.0639003227399\n",
      "gnb 0.318452380952\n",
      "svc 0.85\n",
      "svc5 0.342261904762\n",
      "---------\n",
      "emotions, trustworthiness, entities\n",
      "clf 0.472023809524\n",
      "svr_lin -0.228860159239\n",
      "svr_poly -0.0667960924292\n",
      "gnb 0.318452380952\n",
      "svc 0.85\n",
      "svc5 0.342261904762\n",
      "---------\n",
      "sentiment, emotions, trustworthiness, entities\n",
      "clf 0.41130952381\n",
      "svr_lin -0.251515097147\n",
      "svr_poly -0.0662406150945\n",
      "gnb 0.318452380952\n",
      "svc 0.85\n",
      "svc5 0.342261904762\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVR, SVC\n",
    "\n",
    "dimensions = [\"sentiment\",\"Y\",\"trustworthiness\",\"X\"]\n",
    "emotions = [\"emotion.joy\",\"emotion.fear\",\"emotion.anger\",\"emotion.disgust\",\"emotion.sadness\"]\n",
    "import itertools\n",
    "for i in range(1,len(dimensions)+1):\n",
    "    j = [list(x) for x in list(itertools.combinations(dimensions,i))]\n",
    "    for feat in j:\n",
    "        print (', ').join(feat).replace(\"X\",\"entities\").replace(\"Y\",\"emotions\")\n",
    "        if (\"X\" in feat):\n",
    "            feat = [x for x in feat if x != \"X\"]\n",
    "            feat = feat + ent\n",
    "        if (\"Y\" in feat):\n",
    "            feat = [x for x in feat if x != \"Y\"]\n",
    "            feat = feat + emotions\n",
    "        X = pd2[feat]\n",
    "        y_clf = np.asarray(pd2['overallQuality'], dtype=\"|S6\")\n",
    "        y_gnb = np.asarray(pd2['overallQuality'], dtype=\"|S6\")\n",
    "        y_svr_lin = np.asarray(pd2['overallQuality'])\n",
    "        y_svr_poly = np.asarray(pd2['overallQuality'])\n",
    "        y_class = np.asarray([0 if x<=3 else 1 for x in pd2['overallQuality']])\n",
    "        clf = SGDClassifier(alpha=0.00005, n_iter=1000)\n",
    "        svr_lin = SVR(kernel='linear', C=1e3)\n",
    "        svr_poly = SVR(kernel='poly', C=1e3, degree=2)\n",
    "        gnb = GaussianNB()\n",
    "        svc = SVC(kernel='linear', C=1e3)\n",
    "        #clf.fit(X, y_clf)\n",
    "        #svr_lin.fit(X, y_svr_lin)\n",
    "        #svr_poly.fit(X, y_svr_poly)\n",
    "        #gnb.fit(X, y_gnb)\n",
    "        \n",
    "        scores_clf = cross_validation.cross_val_score(clf, X, y_clf, cv=10)\n",
    "        scores_svr_lin = cross_validation.cross_val_score(svr_lin, X, y_svr_lin, cv=10)\n",
    "        scores_svr_poly = cross_validation.cross_val_score(svr_poly, X, y_svr_poly, cv=10)\n",
    "        scores_gnb = cross_validation.cross_val_score(gnb, X, y_gnb, cv=10)\n",
    "        scores_svc = cross_validation.cross_val_score(svc,X, y_class, cv=10)\n",
    "        scores_svc5 = cross_validation.cross_val_score(svc,X, y_clf, cv=10)\n",
    "        print \"clf\",np.mean(scores_clf)\n",
    "        print \"svr_lin\",np.mean(scores_svr_lin)\n",
    "        print \"svr_poly\",np.mean(scores_svr_poly)\n",
    "        print \"gnb\",np.mean(scores_gnb)\n",
    "        print \"svc\",np.mean(scores_svc)\n",
    "        print \"svc5\",np.mean(scores_svc5)\n",
    "        print \"---------\"      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trustworthiness']\n"
     ]
    }
   ],
   "source": [
    "print [x for x in feat if x not in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment;emotion.joy;emotion.fear;emotion.anger;emotion.disgust;emotion.sadness;http://dbpedia.org/resource/Measles;MMR;MMR vaccine;http://dbpedia.org/resource/Centers_for_Disease_Control_and_Prevention;http://dbpedia.org/resource/United_States;http://dbpedia.org/resource/Mumps;official;flu vaccine;http://dbpedia.org/resource/Merck_&_Co.;http://dbpedia.org/resource/United_Kingdom;varicella vaccine;http://dbpedia.org/resource/Fever;fraud;http://dbpedia.org/resource/Andrew_Wakefield;public health;Vaccine Research Group;http://dbpedia.org/resource/The_Walt_Disney_Company;http://dbpedia.org/resource/Disneyland;http://dbpedia.org/resource/Europe;http://dbpedia.org/resource/Influenza;http://dbpedia.org/resource/Pertussis;pharmaceutical companies;http://dbpedia.org/resource/Advisory_Committee_on_Immunization_Practices;http://dbpedia.org/resource/William_Thompson_(Medal_of_Honor,_1950);scientist;http://dbpedia.org/resource/Autism;immune systems;US;http://dbpedia.org/resource/Rubella;East Anglia;http://dbpedia.org/resource/London;National Health GP;pharmaceutical advertising;Poland;Roger Buttery;immune system;Americans.;Disney;http://dbpedia.org/resource/Canada;http://dbpedia.org/resource/Cough;http://dbpedia.org/resource/Cambridge;http://dbpedia.org/resource/Supreme_Court_of_the_United_States;http://dbpedia.org/resource/Diarrhea;Public Health Laboratory;Huntingdon Health Department;http://dbpedia.org/resource/Wales;America;http://dbpedia.org/resource/Zagreb;http://dbpedia.org/resource/China;http://dbpedia.org/resource/Eric_Cantor;http://dbpedia.org/resource/Weston_A._Price_Foundation;JAMA Pediatrics;http://dbpedia.org/resource/California;Sally Fallon Morell;Shane Ellison;president;100%;86%;90%;95%;99%;Dr. Christenson;Dawn Papple;Global Vaccine Institute;http://dbpedia.org/resource/Christmas;http://dbpedia.org/resource/Indiana;Adam McLean;http://dbpedia.org/resource/Paul_Offit;Quebec;http://dbpedia.org/resource/Indianapolis;http://dbpedia.org/resource/Los_Angeles;USA Today;http://dbpedia.org/resource/Basketball;http://dbpedia.org/resource/Browning,_Montana;http://dbpedia.org/resource/Pneumonia;CHOP;http://dbpedia.org/resource/Montana;Quebec City;http://dbpedia.org/resource/India;Super Bowl Village;http://dbpedia.org/resource/Yosemite,_New_South_Wales;Browning schools;Adverse Reaction Dept.;Browning;Public Health;Boulianne N;J Public Health.;J Epidemiol.;Barratta;http://dbpedia.org/resource/Florida;Davis;http://dbpedia.org/resource/West_Virginia;http://dbpedia.org/resource/Cancer;http://dbpedia.org/resource/Corpus_Christi,_Texas;Mexico;http://dbpedia.org/resource/Texas;measles.;Marcella;Dr. Bob Sears;http://dbpedia.org/resource/Jay_Gordon;Disneyland;http://dbpedia.org/resource/California_Department_of_Public_Health;http://dbpedia.org/resource/Twitter;http://dbpedia.org/resource/Facebook;CDC;http://dbpedia.org/resource/Orange_County,_California;ASD;David Gorski;Mickey;Google University;thimerosal;Utah;YPDC;Japan;CDPH;Yokohama Psycho-Developmental Clinic;Disney California Adventure Park;Dr. Ron Chapman;http://dbpedia.org/resource/Government;DeStefano;director;red rash;Universal Studios Orlando;MCH;http://dbpedia.org/resource/Nagoya_University;Brian Hooker;officer;writer;Kanto;http://dbpedia.org/resource/Jenny_McCarthy;Evan;William Thompson;Wakefield;http://dbpedia.org/resource/Juntendo_University;Nakia S. Clemmons;overseas travel;http://dbpedia.org/resource/World_Health_Organization;Americas;National Center for Immunization and Respiratory Disease;http://dbpedia.org/resource/Illinois;Immunization Services Division;http://dbpedia.org/resource/Nevada;http://dbpedia.org/resource/Washington,_D.C.;http://dbpedia.org/resource/National_Center_for_Immunization_and_Respiratory_Diseases;Gregory S. Wallace;http://dbpedia.org/resource/United_Arab_Emirates;http://dbpedia.org/resource/Azerbaijan;http://dbpedia.org/resource/Maryland;Amy Parker Fiebelkorn;Paul A. Gastanaduy;Susan B. Redd;Washington;Melinda Wharton;William Bellini;Kristin Pope;http://dbpedia.org/resource/Mexico;Office of Policy;Jennifer Rota;http://dbpedia.org/resource/Qatar;http://dbpedia.org/resource/Indonesia;http://dbpedia.org/resource/Pakistan;http://dbpedia.org/resource/Singapore;Paul Rota;Kyrgyzstan;Germany;11 months;12 months;21 days;70%;Maimuna Majumder;Dr. George Rutherford;http://dbpedia.org/resource/Reuters;http://dbpedia.org/resource/Massachusetts_Institute_of_Technology;Boston Children's Hospital;MOBILE DEVICE;http://dbpedia.org/resource/David_Geffen_School_of_Medicine_at_UCLA;vice chair;http://dbpedia.org/resource/San_Francisco;50 percent;86 percent;99 percent;7 percent;four days;two hours;http://dbpedia.org/resource/NPR;Eric Handler;http://dbpedia.org/resource/Los_Angeles_Times;Hensley;Kaplan;50%;96%;Anita Gore;http://dbpedia.org/resource/Utah;SACRAMENTO;Western Europe;http://dbpedia.org/resource/Alameda,_California;http://dbpedia.org/resource/Philippines;http://dbpedia.org/resource/Vietnam;http://dbpedia.org/resource/San_Diego;Orange;Pasadena;Riverside;nine days;21 years;8 months;Healthcare providers;Disneyland Resort Theme Parks;http://dbpedia.org/resource/State_health_agency;MMR vaccine*;CDC.;healthcare facilities;http://dbpedia.org/resource/Chickenpox;incubation period;AZ;UT;WA;4 days;16.5 years;10 months;15 months;12 years;57 years;6 months;10 days;12 days;14 days;2 hours;20 mins;28 days;12%;15%;31%;55%;RE;Disneyland Resort;http://dbpedia.org/resource/Anaheim,_California;Maggie;http://dbpedia.org/resource/Acute_lymphoblastic_leukemia;Phoenix Children’s Hospital;Eli;http://dbpedia.org/resource/Arizona;Dr. Tim Jacks;CareBridge Journal;PCH East Valley Specialty Clinic;American Board of Pediatrics;American Academy of Pediatrics.;Elmhurst;Anna;20 percent;ten months;three week;25 years;3%;http://dbpedia.org/resource/Smallpox;http://dbpedia.org/resource/Jeffrey_Kluger;http://dbpedia.org/resource/Time_(magazine);http://dbpedia.org/resource/Poliomyelitis;master;California;cancer;1 month;Mike Adams;VARIVAX;mainstream media;Varivax;NaturalNews.com;researcher;CWC;toxic chemicals;Certificate of Excellence;potassium chloride;brain cells;abdominal pain;aspirin;skin disorders;food supply;Food Forensics;food science;Natural Science Journal;Bell;CWC Labs;neomycin;Arial Software;content management system;EDTA;technology company;founder;founding editor;food safety;BenBella Books;Asia;executive director;pet food;Consumer Wellness Center;fast food;publisher;0%;Mickey Mouse;John Green;http://dbpedia.org/resource/B.o.B;world history;professor;one day;President Obama;online forums;vaxed;http://dbpedia.org/resource/Kristin_Cavallari;the house;Fifteen years;two decades;2 month;3 years;http://dbpedia.org/resource/Katie_Couric;Southern California amusement park;http://dbpedia.org/resource/Brendan_Nyhan;Ms. Jolie;LDI Center for Health Incentives and Behavioral Economics;Alison Buttenheim;http://dbpedia.org/resource/University_of_Pennsylvania_School_of_Nursing;http://dbpedia.org/resource/Leonard_Davis_Institute_of_Health_Economics;Los Angeles;Senior Fellow;Assistant Professor;Faculty Affiliate;Center for Public Health Initiatives;news media;one month;medical care;Dr. Sherri Tenpenny;media outlets;Australia;http://dbpedia.org/resource/United_States_Congress;http://dbpedia.org/resource/Food_and_Drug_Administration;shut down;stem cell;http://dbpedia.org/resource/Kim_Jong-il;Hitler;Stalin;10 miles;2 months;5 months;60 years;4 years;http://dbpedia.org/resource/Disney_California_Adventure;8-year;Dr. Suzanne Humphries;http://dbpedia.org/resource/Sweden;pharmaceutical industry;vitamin C;Health Impact News;Swedish Institute of Infectious Disease Control;News Editor;Victoria Romanus;http://dbpedia.org/resource/New_England;Roman Bystrianyk;England;http://dbpedia.org/resource/Asthma;http://dbpedia.org/resource/The_New_York_Times;http://dbpedia.org/resource/Jane_Brody;http://dbpedia.org/resource/Fred_R._Klenner;http://dbpedia.org/resource/New_York_City;http://dbpedia.org/resource/American_Journal_of_Epidemiology;Department of Epidemiology Swedish Institute of Infectious Disease Control;http://dbpedia.org/resource/Diphtheria;adverse reactions;http://dbpedia.org/resource/Journal_of_the_American_Medical_Association;Pediatric Infectious Disease Journal;http://dbpedia.org/resource/Frederick_Mosteller;http://dbpedia.org/resource/United_States_Senate;http://dbpedia.org/resource/Thomas_C._Chalmers;Lisa Belkin;P. J. Lachmann;B. Goldman;Proceedings Royal Society of Medicine;http://dbpedia.org/resource/Maine;D. L. Levy;MERK;Rob Dew;reporter;http://dbpedia.org/resource/Coeliac_disease;http://dbpedia.org/resource/Justin_Bieber;medical degree;internet age;air travel;http://dbpedia.org/resource/Africa;http://dbpedia.org/resource/Asia;two months;50 years;80%;85%;97%;Kathleen Harriman;Disneyland California Adventure Park;State of Health;Dr. Erica Pan;http://dbpedia.org/resource/Alameda_County,_California;http://dbpedia.org/resource/Walt_Disney_Parks_and_Resorts;Officer;Deputy Chief;NPR;Scott Hensley;medical officer;Dr. Pamela Hymel;KQED;Nancy Shute;http://dbpedia.org/resource/Associated_Press;1 year;flu shots;Lancet;http://dbpedia.org/resource/Kearny,_Arizona;Dr. Eric Ball;Crystal McDonald;http://dbpedia.org/resource/Huntington_Beach,_California;windows;Missy Foster;http://dbpedia.org/resource/Huntington_Beach_High_School;Kearny school;http://dbpedia.org/resource/Palm_Desert_High_School;http://dbpedia.org/resource/Pinal_County,_Arizona;White House;http://dbpedia.org/resource/Lagunitas,_California;http://dbpedia.org/resource/Phoenix,_Arizona;http://dbpedia.org/resource/Nebraska;San Francisco;http://dbpedia.org/resource/Riverside_County,_California;http://dbpedia.org/resource/National_Vaccine_Information_Center;http://dbpedia.org/resource/John_Carroll_(actor);http://dbpedia.org/resource/Tetanus;http://dbpedia.org/resource/Marin_County,_California;Super Bowl;Lagunitas Elementary;Orange County Health Agency;Kelly McMenimen;Tobias;Lagunitas Elementary School;http://dbpedia.org/resource/Minnesota;http://dbpedia.org/resource/New_York;Tiffany Magee;Matt Zahn;Ciel Lorenzen;Advanced Placement;superintendent;Barbara Loe Fisher;Norm Warren;medical director;Griffin. Griffin;social media;http://dbpedia.org/resource/Toronto;York Region Public Health;Jennifer Hibben-White;Markham;http://dbpedia.org/resource/Google;Australian Privacy Principles;Aurelia;30 minutes;20 YEARS;15 days;1 hour;15-day;3 year;7 days;http://dbpedia.org/resource/Journal_of_Clinical_Microbiology;http://dbpedia.org/resource/Council_on_Foreign_Relations;Leslie Manookian;Office of Medical and Scientific Justice;http://dbpedia.org/resource/CNN;Global Research;Fox;OMSJ;15-month;two-week;1 day;94%;polio vaccine;http://dbpedia.org/resource/Johns_Hopkins_Hospital;http://dbpedia.org/resource/Johns_Hopkins;Johns Hopkins Medicine;http://dbpedia.org/resource/CNBC;corporate media;Eurosurveillance;Pediatric Child Health;Laura Hayes;vaccinees;Schwartz;20 years;Twenty years;eight days;five weeks;four weeks;seven days;14-month;two-year;Dr. James Cherry;Health Advisory;http://dbpedia.org/resource/UCLA_School_of_Nursing;civil rights;asymptomatic;Dr. Pan;America’s school;92%;100 percent;one percent;90 percent;17 years;30 years;Polio vaccine;Big Pharma;http://dbpedia.org/resource/Jake_Tapper;President;http://dbpedia.org/resource/Federal_government_of_the_United_States;CDC’s National Center for Infectious Diseases;http://dbpedia.org/resource/Barack_Obama;http://dbpedia.org/resource/Jonas_Salk;http://dbpedia.org/resource/Sanjay_Gupta;http://dbpedia.org/resource/Ohio;http://dbpedia.org/resource/Federal_Reserve_System;General Vivek Murphy;http://dbpedia.org/resource/RCA;http://dbpedia.org/resource/DuPont;http://dbpedia.org/resource/Chase_(bank);http://dbpedia.org/resource/Trilateral_Commission;Rockefeller;Chairman;communications industry;Bones Society;http://dbpedia.org/resource/Standard_Oil;insurance companies;London;2014 year;fair use;http://dbpedia.org/resource/The_New_England_Journal_of_Medicine;http://dbpedia.org/resource/Morbidity_and_Mortality_Weekly_Report;Centre for Research on Globalization;Center of Research on Globalization;52 percent;95 percent;Measles Mary;http://dbpedia.org/resource/American_School_for_the_Deaf;http://dbpedia.org/resource/Clinical_Infectious_Diseases;http://dbpedia.org/resource/Middle_East;http://dbpedia.org/resource/Chris_Christie;http://dbpedia.org/resource/Neurological_disorder;Practice of Clinical Virology;http://dbpedia.org/resource/Leo_Kanner;Arie J. Zuckerman;http://dbpedia.org/resource/USA_Today;Alex Berezow;Redditor;Syria;Playboy Playmate;Antivaccinationists;media attention;http://dbpedia.org/resource/The_Sydney_Morning_Herald;http://dbpedia.org/resource/Oxford_Journal;22-year;Paul Joseph Watson;Greg Wallace;http://dbpedia.org/resource/National_Institute_of_Allergy_and_Infectious_Diseases;Cristina Cassetti;octogenarians;program officer;88 percent;97 percent;four years;3 percent;Wilbert van Panhuis;http://dbpedia.org/resource/University_of_Pittsburgh_Graduate_School_of_Public_Health;Pitt Public Health;Project Tycho®;assistant professor;investigator;one-week;6 years;Boston Children’s Hospital’s Majumder;Boston Children’s Hospital;weakened immune systems;Health Map Computational Epidemiology;http://dbpedia.org/resource/Anne_Schuchat;JAMA Pediatrics.;96 percent;two years;43%;56%;http://dbpedia.org/resource/William_Schaffner;http://dbpedia.org/resource/Vanderbilt_University_School_of_Medicine;Live Science;http://dbpedia.org/resource/Nashville,_Tennessee;http://dbpedia.org/resource/Tennessee;92 percent;JAMA;Colorado;research fellow;HealthDay;three months;two percent;Patsy Stinchfield;Laura Bredesen;Ben;Children’s Hospitals and Clinics of Minnesota;http://dbpedia.org/resource/Encephalitis;director of Infection Prevention and Control;unimmunized;Ebola;brain damage;Dr. Eric Handler;pneumonia;Orange County;three weeks;three years;1 percent;3.5 years;5 percent;5 years;2-year;hepatitis B vaccine;hepatitis A vaccine;hepatitis;press release;http://dbpedia.org/resource/Idaho;Mississippi;35 months;94.2%;0.1%;1.7%;6.5%;Jason Millman;River Springs Charter School;Ocean Grove Charter School;http://dbpedia.org/resource/Yuba_County,_California;http://dbpedia.org/resource/Alaska;http://dbpedia.org/resource/Mississippi;Bloomberg;http://dbpedia.org/resource/Temecula,_California;http://dbpedia.org/resource/Boulder_Creek_(Colorado);http://dbpedia.org/resource/San_Luis_Obispo,_California;Silicon Valley;Carmichael;Santa Cruz;Sonoma;Fresno;http://dbpedia.org/resource/Sacramento,_California;Malibu;Marin;2.5 percent;0.77 percent;3.15 percent;59.1 percent;65.3 percent;five percent;3.2 percent;5.3 percent;10 percent;51 percent;75 percent;76 percent;94 percent;http://dbpedia.org/resource/Rob_Schneider;http://dbpedia.org/resource/The_Washington_Post;mmr;New York;Kabbalah Children's Academy;National Enterovirus Surveillance System;http://dbpedia.org/resource/The_Home_Depot;meningitis;http://dbpedia.org/resource/Beverly_Hills,_Marion_County,_West_Virginia;http://dbpedia.org/resource/The_Hollywood_Reporter;http://dbpedia.org/resource/Santa_Monica,_California;Glyphosate;Waldorf Early Childhood Center;science education;State Farm SNL;health insurance company;Marina Del Rey;Italy;utero;http://dbpedia.org/resource/Los_Angeles_County,_California;Ontario;Diazanon;Vanderbilt School of Medicine;Nashville;Dursban;five minutes;7-month;57%;68%;http://dbpedia.org/resource/Washington_Township,_Macomb_County,_Michigan;http://dbpedia.org/resource/Colorado;Renee Schiavone;Journal of the American Medical Association’s Pediatrics;Editor;http://dbpedia.org/resource/New_Jersey;http://dbpedia.org/resource/South_Dakota;http://dbpedia.org/resource/Delaware;http://dbpedia.org/resource/Michigan;http://dbpedia.org/resource/Pennsylvania;D.C.;http://dbpedia.org/resource/Oregon;Georgia;45 percent;6 percent;six weeks;70 years;Genetic Characterization and Sequencing;Age of Autism;MMR vaccine.;Andreas Bollmann;http://dbpedia.org/resource/College_of_Physicians_of_Philadelphia;Bennett Lorber;History of Vaccines;Schamberg JF;Historical Medical Library;http://dbpedia.org/resource/Celgene;http://dbpedia.org/resource/University;Philadelphia;Pharmaceutical companies;Joseph Camardo;WB Saunders;Senior Vice President;advisory board;Santa Monica;G;1%;5%;one hand;2 days;45%;6%;http://dbpedia.org/resource/Italy;http://dbpedia.org/resource/American_Journal_of_Public_Health;Sayer Ji;http://dbpedia.org/resource/Rio_de_Janeiro;Canadian Journal of Public Health;L E Markowitz;http://dbpedia.org/resource/Community_development_corporation;http://dbpedia.org/resource/South_African_Medical_Journal;Sociedade Brasileira de Medicina Tropical;Orenstein;http://dbpedia.org/resource/Cape_Town;Gardasil;Cape Town–a;China;http://dbpedia.org/resource/Bill_Gates;Public Health.;6N Coetzee;http://dbpedia.org/resource/South_Africa;Montana;http://dbpedia.org/resource/Music_of_North_Carolina;http://dbpedia.org/resource/Bill_&_Melinda_Gates_Foundation;de Oliveira;Brunell;G De Serres;Brazil;G Visser;Le Hénaff;P Barron;M Davis;R G Moellenberg;J R Joly;Southern California;http://dbpedia.org/resource/Tropical_disease;Dr .James Cherry;University of California;Sacramento;42 days\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-37ec1808cfea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mscores_svr_poly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvr_poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_svr_poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mscores_gnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_gnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mscores_all_svc5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"|S6\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0mscores_svc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"clf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_clf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dceolin/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dceolin/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2002\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2004\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dceolin/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dceolin/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3290\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3291\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dceolin/anaconda/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1945\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "#import documents\n",
    "#import assessments\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.externals import joblib\n",
    "import csv\n",
    "\n",
    "gnb = GaussianNB()\n",
    "pd.options.mode.chained_assignment = None \n",
    "ent = []\n",
    "\n",
    "pd2 = pd.read_csv(\"~/document.csv\",quotechar=\"\\\"\",sep=\",\",header=0)\n",
    "for i in range(0,50):\n",
    "    for x in json.loads(pd2.iloc[i].entities):\n",
    "        colname = x['disambiguated']['dbpedia'] if 'disambiguated' in x and 'dbpedia' in x['disambiguated'] else x['text']\n",
    "        pd2[colname] = np.zeros(50)\n",
    "        ent.append(colname)\n",
    "for i in range(0,50):\n",
    "    for x in json.loads(pd2.iloc[i].entities):\n",
    "        colname = x['disambiguated']['dbpedia'] if 'disambiguated' in x and 'dbpedia' in x['disambiguated'] else x['text']\n",
    "        pd2[colname][i] = float(x['relevance'])\n",
    "\n",
    "#print pd2\n",
    "\n",
    "assessments = pd.read_csv(\"./ass_j.csv\",sep=\",\", header=0,)\n",
    "\n",
    "grouped_assessment = assessments.groupby('target').mean()#['overallQuality']\n",
    " \n",
    "x = [x for x in pd2['url'] if x in assessments['target']]\n",
    "pd3 = pd2.merge(assessments,how=\"outer\",left_on='url', right_on='target' )\n",
    "pd2 = pd2.set_index('url')\n",
    "\n",
    "pd2 = pd.concat([pd2, grouped_assessment], axis=1, join='inner')\n",
    "\n",
    "\n",
    "l = [x for x in list(pd2.columns.values) if x not in list(assessments.columns.values)]\n",
    "l = [x for x in l if x not in ['entities','title','source','_id']]\n",
    "#print pd2.columns.values\n",
    "X = pd2[l]\n",
    "X2 = pd3[l]\n",
    "print \";\".join(X.columns.values)\n",
    "y = np.asarray(pd2['overallQuality'])\n",
    "\n",
    "#X = pd2[x for x in list(pd2.columns.values) if x not in list(assessments.columns.values)]\n",
    "for x in ['overallQuality']:\n",
    "    y_clf = np.asarray(pd2[x], dtype=\"|S6\")\n",
    "    y_gnb = np.asarray(pd2[x], dtype=\"|S6\")\n",
    "    y_svr_lin = np.asarray(pd2[x])\n",
    "    y_svr_poly = np.asarray(pd2[x])\n",
    "    y_class = np.asarray([0 if x<=3 else 1 for x in pd3['overallQuality']])\n",
    "    clf = SGDClassifier(alpha=0.00005, n_iter=1000)\n",
    "    svr_lin = SVR(kernel='linear', C=1e3)\n",
    "    svr_poly = SVR(kernel='poly', C=1e3, degree=2)\n",
    "    gnb = GaussianNB()\n",
    "    svc = SVC(kernel='linear', C=1e3)\n",
    "    clf.fit(X, y_clf)\n",
    "    joblib.dump(clf,'clf.pkl')\n",
    "    '''svr_lin.fit(X, y_svr_lin)\n",
    "    svr_poly.fit(X, y_svr_poly)\n",
    "    gnb.fit(X, y_gnb)\n",
    "    print X.shape'''\n",
    "    \n",
    "    scores_clf = cross_validation.cross_val_score(clf, X, y_clf, cv=10)\n",
    "    scores_svr_lin = cross_validation.cross_val_score(svr_lin, X, y_svr_lin, cv=10)\n",
    "    scores_svr_poly = cross_validation.cross_val_score(svr_poly, X, y_svr_poly, cv=10)\n",
    "    scores_gnb = cross_validation.cross_val_score(gnb, X, y_gnb, cv=10)\n",
    "    scores_all_svc5 = cross_validation.cross_val_score(svc, X2, np.asarray(pd3[x], dtype=\"|S6\"), cv=10)\n",
    "    scores_svc = cross_validation.cross_val_score(svc,X2, y_class, cv=10)\n",
    "    print \"clf\",np.mean(scores_clf)\n",
    "    print \"svr_lin\",np.mean(scores_svr_lin)\n",
    "    print \"svr_poly\",np.mean(scores_svr_poly)\n",
    "    print \"gnb\",np.mean(scores_gnb)\n",
    "    print \"svc2_all\",np.mean(scores_svc)\n",
    "    print \"svc5_all\",np.mean(scores_all_svc5)\n",
    "    print \"---------\"\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "clf 0.0819444444444\n",
      "svr_lin -0.233241348516\n",
      "svr_poly -0.285108917838\n",
      "gnb 0.2625\n",
      "svc2_all 0.548484848485\n",
      "svc5_all 0.297724497724\n",
      "---------\n",
      "emotions\n",
      "clf 0.0644444444444\n",
      "svr_lin -0.563215981807\n",
      "svr_poly -0.870505737047\n",
      "gnb 0.125555555556\n",
      "svc2_all 0.451515151515\n",
      "svc5_all 0.318018093018\n",
      "---------\n",
      "trustworthiness\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['trustworthiness'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3a8866d36670>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0memotions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0my_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpd3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'overallQuality'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0my_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'overallQuality'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"|S6\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dceolin/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1989\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1990\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1991\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1992\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1993\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dceolin/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2033\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2034\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2035\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2036\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dceolin/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1212\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['trustworthiness'] not in index\""
     ]
    }
   ],
   "source": [
    "dimensions = [\"sentiment\",\"Y\",\"trustworthiness\",\"X\"]\n",
    "emotions = [\"emotion.joy\",\"emotion.fear\",\"emotion.anger\",\"emotion.disgust\",\"emotion.sadness\"]\n",
    "import itertools\n",
    "for i in range(1,len(dimensions)+1):\n",
    "    j = [list(x) for x in list(itertools.combinations(dimensions,i))]\n",
    "    for feat in j:\n",
    "        print (', ').join(feat).replace(\"X\",\"entities\").replace(\"Y\",\"emotions\")\n",
    "        if (\"X\" in feat):\n",
    "            feat = [x for x in feat if x != \"X\"]\n",
    "            feat = feat + ent\n",
    "        if (\"Y\" in feat):\n",
    "            feat = [x for x in feat if x != \"Y\"]\n",
    "            feat = feat + emotions\n",
    "        X = pd2[feat]\n",
    "        X2 = pd3[feat]\n",
    "        y_class = np.asarray([0 if x<=3 else 1 for x in pd3['overallQuality']])\n",
    "        y_clf = np.asarray(pd2['overallQuality'], dtype=\"|S6\")\n",
    "        y_gnb = np.asarray(pd2['overallQuality'], dtype=\"|S6\")\n",
    "        y_svr_lin = np.asarray(pd2['overallQuality'])\n",
    "        y_svr_poly = np.asarray(pd2['overallQuality'])\n",
    "        clf = SGDClassifier(alpha=0.00005, n_iter=1000)\n",
    "        svr_lin = SVR(kernel='linear', C=1e3)\n",
    "        svr_poly = SVR(kernel='poly', C=1e3, degree=2)\n",
    "        gnb = GaussianNB()\n",
    "        clf.fit(X, y_clf)\n",
    "        svr_lin.fit(X, y_svr_lin)\n",
    "        svr_poly.fit(X, y_svr_poly)\n",
    "        gnb.fit(X, y_gnb)\n",
    "        \n",
    "        scores_clf = cross_validation.cross_val_score(clf, X, y_clf, cv=10)\n",
    "        scores_svr_lin = cross_validation.cross_val_score(svr_lin, X, y_svr_lin, cv=10)\n",
    "        scores_svr_poly = cross_validation.cross_val_score(svr_poly, X, y_svr_poly, cv=10)\n",
    "        scores_gnb = cross_validation.cross_val_score(gnb, X, y_gnb, cv=10)\n",
    "        scores_all_svc5 = cross_validation.cross_val_score(svc, X2, np.asarray(pd3['overallQuality'], dtype=\"|S6\"), cv=10)\n",
    "        scores_svc = cross_validation.cross_val_score(svc,X2, y_class, cv=10)\n",
    "        \n",
    "        print \"clf\",np.mean(scores_clf)\n",
    "        print \"svr_lin\",np.mean(scores_svr_lin)\n",
    "        print \"svr_poly\",np.mean(scores_svr_poly)\n",
    "        print \"gnb\",np.mean(scores_gnb)\n",
    "        print \"svc2_all\",np.mean(scores_svc)\n",
    "        print \"svc5_all\",np.mean(scores_all_svc5)\n",
    "        print \"---------\"      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000       -0.068923  -0.161310        -0.012232\n",
      "overallQuality  -0.068923        1.000000   0.306377         0.814028\n",
      "sentiment       -0.161310        0.306377   1.000000         0.280143\n",
      "trustworthiness -0.012232        0.814028   0.280143         1.000000\n",
      "sentiment\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000        0.093340   0.121328         0.171270\n",
      "overallQuality   0.093340        1.000000   0.306377         0.814028\n",
      "sentiment        0.121328        0.306377   1.000000         0.280143\n",
      "trustworthiness  0.171270        0.814028   0.280143         1.000000\n",
      "trustworthiness\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000        0.199459   0.192893         0.217135\n",
      "overallQuality   0.199459        1.000000   0.306377         0.814028\n",
      "sentiment        0.192893        0.306377   1.000000         0.280143\n",
      "trustworthiness  0.217135        0.814028   0.280143         1.000000\n",
      "sources\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000        0.290637   0.090771         0.450985\n",
      "overallQuality   0.290637        1.000000   0.306377         0.814028\n",
      "sentiment        0.090771        0.306377   1.000000         0.280143\n",
      "trustworthiness  0.450985        0.814028   0.280143         1.000000\n",
      "titles\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000       -0.068607  -0.072244         0.081726\n",
      "overallQuality  -0.068607        1.000000   0.306377         0.814028\n",
      "sentiment       -0.072244        0.306377   1.000000         0.280143\n",
      "trustworthiness  0.081726        0.814028   0.280143         1.000000\n",
      "all\n",
      "                        0  overallQuality  sentiment  trustworthiness\n",
      "0                1.000000        0.203443   0.157513         0.156431\n",
      "overallQuality   0.203443        1.000000   0.306377         0.814028\n",
      "sentiment        0.157513        0.306377   1.000000         0.280143\n",
      "trustworthiness  0.156431        0.814028   0.280143         1.000000\n",
      "                 overallQuality  accuracy  completeness  neutrality  \\\n",
      "overallQuality         1.000000  0.889662      0.694396    0.461334   \n",
      "accuracy               0.889662  1.000000      0.765922    0.568996   \n",
      "completeness           0.694396  0.765922      1.000000    0.701420   \n",
      "neutrality             0.461334  0.568996      0.701420    1.000000   \n",
      "relevance              0.634596  0.608054      0.654732    0.311987   \n",
      "trustworthiness        0.804964  0.881774      0.725162    0.618599   \n",
      "readability            0.667052  0.677106      0.578546    0.403131   \n",
      "precision              0.768356  0.814074      0.775485    0.493895   \n",
      "\n",
      "                 relevance  trustworthiness  readability  precision  \n",
      "overallQuality    0.634596         0.804964     0.667052   0.768356  \n",
      "accuracy          0.608054         0.881774     0.677106   0.814074  \n",
      "completeness      0.654732         0.725162     0.578546   0.775485  \n",
      "neutrality        0.311987         0.618599     0.403131   0.493895  \n",
      "relevance         1.000000         0.578497     0.644123   0.724098  \n",
      "trustworthiness   0.578497         1.000000     0.711564   0.790643  \n",
      "readability       0.644123         0.711564     1.000000   0.658378  \n",
      "precision         0.724098         0.790643     0.658378   1.000000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "document = pd.read_csv(\"./document.csv\",sep=\";\",header=0)\n",
    "best = pd.read_csv(\"./best_j.csv\",sep=\";\", header=0,)\n",
    "sequence = pd.read_csv(\"./sequence_old.csv\",sep=\",\", header=0,)\n",
    "\n",
    "#print document \n",
    "k = [document.loc[document[\"_id\"] == \"ObjectId(%s)\" % x['$oid']]['url'] for y in sequence.loc[sequence['user'].notnull()]['sequence'].map(json.loads) for x in y]\n",
    "k1 = [x.tolist()[0] for x in k]\n",
    "\n",
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "t1 = ['entities','sentiment','trustworthiness','sources','titles','all']\n",
    "\n",
    "for t in t1:\n",
    "    k = [x.replace(\"[ \",\"['\").replace(\"]\",\"']\").replace(\", \",\"', '\") for x in best.loc[best['key'] == t]['articles'] if len(x)>0]\n",
    "    k = [ast.literal_eval(x) for x in k if x != \"[\\']\"]\n",
    "    n = Counter([x for y in k for x in y])\n",
    "    tot = Counter(k1)\n",
    "    frac = dict()\n",
    "    for v in n:\n",
    "        frac[v] = (n[v]+1)/(float(tot[v])+2)\n",
    "    frac = pd.Series(frac)\n",
    "    k = grouped_assessment['overallQuality']\n",
    "    k = pd.concat([frac, k,pd2['sentiment'],pd2['trustworthiness']], axis=1).fillna(value=0)\n",
    "    print t\n",
    "    print k.loc[k['overallQuality']>0].corr(method=\"spearman\")\n",
    "    \n",
    "print grouped_assessment.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0656689436349\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "dataSetI = [3, 45, 7, 2]\n",
    "dataSetII = [1, 0, 0, 0]\n",
    "result = 1 - spatial.distance.cosine(dataSetI, dataSetII)\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class SVRClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y):\n",
    "        self.classes_, indices = np.unique([\"Low\", \"Medium\", \"High\"],return_inverse=True)\n",
    "        self.majority_ = np.argmax(np.bincount(indices))\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return np.repeat(self.classes_[self.majority_], len(X))\n",
    "    def get_params(self, deep=True):\n",
    "    # suppose this estimator has parameters \"alpha\" and \"recursive\"\n",
    "        return {}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['High' 'Low' 'Medium']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print np.unique([\"Low\", \"Medium\", \"High\"],return_inverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n"
     ]
    }
   ],
   "source": [
    "print len(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WilcoxonResult(statistic=1327.5, pvalue=0.74254178143127447)\n",
      "WilcoxonResult(statistic=1147.0, pvalue=0.43987293045456055)\n",
      "WilcoxonResult(statistic=1295.0, pvalue=0.61210094341467913)\n",
      "WilcoxonResult(statistic=1317.0, pvalue=0.8514552818301987)\n",
      "WilcoxonResult(statistic=1174.5, pvalue=0.54677037468270062)\n",
      "WilcoxonResult(statistic=1224.0, pvalue=0.48080552392505227)\n",
      "WilcoxonResult(statistic=1445.0, pvalue=0.62881760981350787)\n",
      "WilcoxonResult(statistic=1270.0, pvalue=0.96275276314126446)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats \n",
    "assessments = pd.read_csv(\"./ass_j2.csv\",sep=\";\", header=0,)\n",
    "new_assessments = pd.read_csv(\"./new_ass_j.csv\",sep=\";\", header=0,)\n",
    "x = ['overallQuality','accuracy','completeness','neutrality','relevance','trustworthiness','readability','precision']\n",
    "\n",
    "for y in x:\n",
    "    print stats.wilcoxon(assessments[y],new_assessments[y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "34\n",
      "WilcoxonResult(statistic=180.5, pvalue=0.60359714676788101)\n",
      "WilcoxonResult(statistic=165.5, pvalue=0.79655991284515926)\n",
      "WilcoxonResult(statistic=220.5, pvalue=0.80165247020251607)\n",
      "WilcoxonResult(statistic=47.5, pvalue=0.7515290794442091)\n",
      "WilcoxonResult(statistic=168.0, pvalue=0.84764952504786217)\n",
      "WilcoxonResult(statistic=214.0, pvalue=0.69948630563063308)\n",
      "WilcoxonResult(statistic=246.5, pvalue=0.97632365735640358)\n",
      "WilcoxonResult(statistic=196.0, pvalue=0.87150716860569322)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "assessments = pd.read_csv(\"./data3.csv\",sep=\";\", header=0,)\n",
    "new_assessments = pd.read_csv(\"./new_ass.csv\",sep=\";\", header=0,)\n",
    "assessments = assessments.loc[assessments['target'].isin(new_assessments['target']),:]\n",
    "#new_assessments = new_assessments.loc[new_assessments['target'] in assessments['target'],:]\n",
    "                                  #df1.loc[:, df1.loc['a'] > 0]\n",
    "print len(assessments)\n",
    "print len(new_assessments)\n",
    "\n",
    "x = ['overallQuality','accuracy','completeness','neutrality','relevance','trustworthiness','readability','precision']\n",
    "\n",
    "for y in x:\n",
    "    print stats.wilcoxon(assessments[y],new_assessments[y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=2.5, pvalue=0.092591595750229932)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.wilcoxon([75,78,72,72],[89,86,85,85])\n",
    "stats.wilcoxon([63,53,34,34],[48,46,38,39])\n",
    "stats.wilcoxon([89,69,46,63,80,67,77],[89,69,45,64,78,67,76])\n",
    "stats.wilcoxon([-7,9,20,29,-7,20],[38,19,21,25,15,24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
